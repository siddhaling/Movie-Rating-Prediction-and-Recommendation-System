{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Recommender System.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC8dEfluNyxr"
      },
      "source": [
        "**Important**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Before Proceeding you need to download the datasets from https://www.kaggle.com/netflix-inc/netflix-prize-data\n",
        "Otherwise errors will be thrown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SewJKz2_LtTB"
      },
      "source": [
        "# To store the data\n",
        "import pandas as pd\n",
        "\n",
        "# To do linear algebra\n",
        "import numpy as np\n",
        "\n",
        "# To create plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# To create interactive plots\n",
        "from plotly.offline import init_notebook_mode, plot, iplot\n",
        "import plotly.graph_objs as go\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "# To shift lists\n",
        "from collections import deque\n",
        "\n",
        "# To compute similarities between vectors\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# To use recommender systems\n",
        "!pip install scikit-surprise\n",
        "import surprise as sp\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "\n",
        "# To create sparse matrices\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "\n",
        "# To stack sparse matrices\n",
        "from scipy.sparse import vstack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTwS6vCLtTQ"
      },
      "source": [
        "# Load data for all movies\n",
        "movie_titles = pd.read_csv('movie_titles.csv', \n",
        "                           encoding = 'ISO-8859-1', \n",
        "                           header = None, \n",
        "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
        "\n",
        "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
        "movie_titles.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0FloGNLtTe"
      },
      "source": [
        "# Load single data-file\n",
        "df_raw = pd.read_csv('combined_data_1.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
        "\n",
        "\n",
        "# Find empty rows to slice dataframe for each movie\n",
        "tmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\n",
        "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
        "\n",
        "# Shift the movie_indices by one to get start and endpoints of all movies\n",
        "shifted_movie_indices = deque(movie_indices)\n",
        "shifted_movie_indices.rotate(-1)\n",
        "\n",
        "\n",
        "# Gather all dataframes\n",
        "user_data = []\n",
        "\n",
        "# Iterate over all movies\n",
        "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
        "    \n",
        "    # Check if it is the last movie in the file\n",
        "    if df_id_1<df_id_2:\n",
        "        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
        "    else:\n",
        "        tmp_df = df_raw.loc[df_id_1+1:].copy()\n",
        "        \n",
        "    # Create movie_id column\n",
        "    tmp_df['Movie'] = movie_id\n",
        "    \n",
        "    # Append dataframe to list\n",
        "    user_data.append(tmp_df)\n",
        "\n",
        "# Combine all dataframes\n",
        "df = pd.concat(user_data)\n",
        "del user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2,\n",
        "next_movie_id\n",
        "print('Shape User-Ratings:\\t{}'.format(df.shape))\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma2-hozwLtTu"
      },
      "source": [
        "# Get data\n",
        "data = movie_titles['Year'].value_counts().sort_index()\n",
        "\n",
        "# Create trace\n",
        "trace = go.Scatter(x = data.index,\n",
        "                   y = data.values,\n",
        "                   marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = '{} Movies Grouped By Year Of Release'.format(movie_titles.shape[0]),\n",
        "              xaxis = dict(title = 'Release Year'),\n",
        "              yaxis = dict(title = 'Movies'))\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4xtBTR-LtT5"
      },
      "source": [
        "# Get data\n",
        "data = df['Rating'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "# Create trace\n",
        "trace = go.Bar(x = data.index,\n",
        "               text = ['{:.1f} %'.format(val) for val in (data.values / df.shape[0] * 100)],\n",
        "               textposition = 'auto',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               y = data.values,\n",
        "               marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = 'Distribution Of {} Netflix-Ratings'.format(df.shape[0]),\n",
        "              xaxis = dict(title = 'Rating'),\n",
        "              yaxis = dict(title = 'Count'))\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIgxJ_54LtUD"
      },
      "source": [
        "# Get data\n",
        "data = df['Date'].value_counts()\n",
        "data.index = pd.to_datetime(data.index)\n",
        "data.sort_index(inplace=True)\n",
        "\n",
        "# Create trace\n",
        "trace = go.Scatter(x = data.index,\n",
        "                   y = data.values,\n",
        "                   marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = '{} Movie-Ratings Grouped By Day'.format(df.shape[0]),\n",
        "              xaxis = dict(title = 'Date'),\n",
        "              yaxis = dict(title = 'Ratings'))\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh4-9RN-LtUO"
      },
      "source": [
        "##### Ratings Per Movie #####\n",
        "# Get data\n",
        "data = df.groupby('Movie')['Rating'].count().clip(upper=9999)\n",
        "\n",
        "# Create trace\n",
        "trace = go.Histogram(x = data.values,\n",
        "                     name = 'Ratings',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 10000,\n",
        "                                  size = 100),\n",
        "                     marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = go.Layout(title = 'Distribution Of Ratings Per Movie (Clipped at 9999)',\n",
        "                   xaxis = dict(title = 'Ratings Per Movie'),\n",
        "                   yaxis = dict(title = 'Count'),\n",
        "                   bargap = 0.2)\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "##### Ratings Per User #####\n",
        "# Get data\n",
        "data = df.groupby('User')['Rating'].count().clip(upper=199)\n",
        "\n",
        "# Create trace\n",
        "trace = go.Histogram(x = data.values,\n",
        "                     name = 'Ratings',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 200,\n",
        "                                  size = 2),\n",
        "                     marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = go.Layout(title = 'Distribution Of Ratings Per User (Clipped at 199)',\n",
        "                   xaxis = dict(title = 'Ratings Per User'),\n",
        "                   yaxis = dict(title = 'Count'),\n",
        "                   bargap = 0.2)\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQqBGYILtUf"
      },
      "source": [
        "# Filter sparse movies\n",
        "min_movie_ratings = 10000\n",
        "filter_movies = (df['Movie'].value_counts()>min_movie_ratings)\n",
        "filter_movies = filter_movies[filter_movies].index.tolist()\n",
        "\n",
        "# Filter sparse users\n",
        "min_user_ratings = 200\n",
        "filter_users = (df['User'].value_counts()>min_user_ratings)\n",
        "filter_users = filter_users[filter_users].index.tolist()\n",
        "\n",
        "# Actual filtering\n",
        "df_filterd = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n",
        "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
        "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
        "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUGDjkCCLtUs"
      },
      "source": [
        "# Shuffle DataFrame\n",
        "df_filterd = df_filterd.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Testingsize\n",
        "n = 100000\n",
        "\n",
        "# Split train- & testset\n",
        "df_train = df_filterd[:-n]\n",
        "df_test = df_filterd[-n:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k7kQQhILtU2"
      },
      "source": [
        "# Create a user-movie matrix with empty values\n",
        "df_p = df_train.pivot_table(index='User', columns='Movie', values='Rating')\n",
        "print('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\n",
        "df_p.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeDwKgyJLtVE"
      },
      "source": [
        "# Top n movies\n",
        "n = 10\n",
        "\n",
        "# Compute mean rating for all movies\n",
        "ratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n",
        "\n",
        "# Count ratings for all movies\n",
        "ratings_count = df_p.count(axis=0).rename('Rating-Count').to_frame()\n",
        "\n",
        "# Combine ratings_mean, ratings_count and movie_titles\n",
        "ranking_mean_rating = ratings_mean.head(n).join(ratings_count).join(movie_titles.drop('Year', axis=1))\n",
        "\n",
        "\n",
        "# Join labels and predictions\n",
        "df_prediction = df_test.set_index('Movie').join(ratings_mean)[['Rating', 'Rating-Mean']]\n",
        "y_true = df_prediction['Rating']\n",
        "y_pred = df_prediction['Rating-Mean']\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
        "\n",
        "\n",
        "# Create trace\n",
        "trace = go.Bar(x = ranking_mean_rating['Rating-Mean'],\n",
        "               text = ranking_mean_rating['Name'].astype(str) +': '+ ranking_mean_rating['Rating-Count'].astype(str) + ' Ratings',\n",
        "               textposition = 'outside',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               orientation = 'h',\n",
        "               y = list(range(1, n+1)),\n",
        "               marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = 'Ranking Of Top {} Mean-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n",
        "              xaxis = dict(title = 'Mean-Rating',\n",
        "                          range = (4.3, 4.55)),\n",
        "              yaxis = dict(title = 'Movie'))\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzYZX-zMLtVT"
      },
      "source": [
        "\n",
        "# Number of minimum votes to be considered\n",
        "m = 1000\n",
        "\n",
        "# Mean rating for all movies\n",
        "C = df_p.stack().mean()\n",
        "\n",
        "# Mean rating for all movies separatly\n",
        "R = df_p.mean(axis=0).values\n",
        "\n",
        "# Rating count for all movies separatly\n",
        "v = df_p.count().values\n",
        "\n",
        "\n",
        "# Weighted formula to compute the weighted rating\n",
        "weighted_score = (v/ (v+m) *R) + (m/ (v+m) *C)\n",
        "# Sort ids to ranking\n",
        "weighted_ranking = np.argsort(weighted_score)[::-1]\n",
        "# Sort scores to ranking\n",
        "weighted_score = np.sort(weighted_score)[::-1]\n",
        "# Get movie ids\n",
        "weighted_movie_ids = df_p.columns[weighted_ranking]\n",
        "\n",
        "\n",
        "# Join labels and predictions\n",
        "df_prediction = df_test.set_index('Movie').join(pd.DataFrame(weighted_score, index=weighted_movie_ids, columns=['Prediction']))[['Rating', 'Prediction']]\n",
        "y_true = df_prediction['Rating']\n",
        "y_pred = df_prediction['Prediction']\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
        "\n",
        "\n",
        "# Create DataFrame for plotting\n",
        "df_plot = pd.DataFrame(weighted_score[:n], columns=['Rating'])\n",
        "df_plot.index = weighted_movie_ids[:10]\n",
        "ranking_weighted_rating = df_plot.join(ratings_count).join(movie_titles)\n",
        "del df_plot\n",
        "\n",
        "\n",
        "# Create trace\n",
        "trace = go.Bar(x = ranking_weighted_rating['Rating'],\n",
        "               text = ranking_weighted_rating['Name'].astype(str) +': '+ ranking_weighted_rating['Rating-Count'].astype(str) + ' Ratings',\n",
        "               textposition = 'outside',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               orientation = 'h',\n",
        "               y = list(range(1, n+1)),\n",
        "               marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = 'Ranking Of Top {} Weighted-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n",
        "              xaxis = dict(title = 'Weighted Rating',\n",
        "                          range = (4.15, 4.6)),\n",
        "              yaxis = dict(title = 'Movie'))\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TY5BS6EjLtVh"
      },
      "source": [
        "# User index for recommendation\n",
        "user_index = 0\n",
        "\n",
        "# Number of similar users for recommendation\n",
        "n_recommendation = 100\n",
        "\n",
        "# Plot top n recommendations\n",
        "n_plot = 10\n",
        "\n",
        "\n",
        "# Fill in missing values\n",
        "df_p_imputed = df_p.T.fillna(df_p.mean(axis=1)).T\n",
        "\n",
        "# Compute similarity between all users\n",
        "similarity = cosine_similarity(df_p_imputed.values)\n",
        "\n",
        "# Remove self-similarity from similarity-matrix\n",
        "similarity -= np.eye(similarity.shape[0])\n",
        "\n",
        "\n",
        "# Sort similar users by index\n",
        "similar_user_index = np.argsort(similarity[user_index])[::-1]\n",
        "# Sort similar users by score\n",
        "similar_user_score = np.sort(similarity[user_index])[::-1]\n",
        "\n",
        "\n",
        "# Get unrated movies\n",
        "unrated_movies = df_p.iloc[user_index][df_p.iloc[user_index].isna()].index\n",
        "\n",
        "# Weight ratings of the top n most similar users with their rating and compute the mean for each movie\n",
        "mean_movie_recommendations = (df_p_imputed.iloc[similar_user_index[:n_recommendation]].T * similar_user_score[:n_recommendation]).T.mean(axis=0)\n",
        "\n",
        "# Filter for unrated movies and sort results\n",
        "best_movie_recommendations = mean_movie_recommendations[unrated_movies].sort_values(ascending=False).to_frame().join(movie_titles)\n",
        "\n",
        "\n",
        "# Create user-id mapping\n",
        "user_id_mapping = {id:i for i, id in enumerate(df_p_imputed.index)}\n",
        "\n",
        "prediction = []\n",
        "# Iterate over all testset items\n",
        "for user_id in df_test['User'].unique():\n",
        "    \n",
        "    # Sort similar users by index\n",
        "    similar_user_index = np.argsort(similarity[user_id_mapping[user_id]])[::-1]\n",
        "    # Sort similar users by score\n",
        "    similar_user_score = np.sort(similarity[user_id_mapping[user_id]])[::-1]\n",
        "    \n",
        "    for movie_id in df_test[df_test['User']==user_id]['Movie'].values:\n",
        "\n",
        "        # Compute predicted score\n",
        "        score = (df_p_imputed.iloc[similar_user_index[:n_recommendation]][movie_id] * similar_user_score[:n_recommendation]).values.sum() / similar_user_score[:n_recommendation].sum()\n",
        "        prediction.append([user_id, movie_id, score])\n",
        "        \n",
        "\n",
        "# Create prediction DataFrame\n",
        "df_pred = pd.DataFrame(prediction, columns=['User', 'Movie', 'Prediction']).set_index(['User', 'Movie'])\n",
        "df_pred = df_test.set_index(['User', 'Movie']).join(df_pred)\n",
        "\n",
        "\n",
        "# Get labels and predictions\n",
        "y_true = df_pred['Rating'].values\n",
        "y_pred = df_pred['Prediction'].values\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
        "\n",
        "\n",
        "# Create trace\n",
        "trace = go.Bar(x = best_movie_recommendations.iloc[:n_plot, 0],\n",
        "               text = best_movie_recommendations['Name'],\n",
        "               textposition = 'inside',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               orientation = 'h',\n",
        "               y = list(range(1, n_plot+1)),\n",
        "               marker = dict(color = '#db0000'))\n",
        "# Create layout\n",
        "layout = dict(title = 'Ranking Of Top {} Recommended Movies For A User Based On Similarity: {:.4f} RMSE'.format(n_plot, rmse),\n",
        "              xaxis = dict(title = 'Recommendation-Rating',\n",
        "                           range = (4.1, 4.5)),\n",
        "              yaxis = dict(title = 'Movie'))\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLfsCqK9LtVs"
      },
      "source": [
        "# Load dataset into surprise specific data-structure\n",
        "data = sp.Dataset.load_from_df(df_filterd[['User', 'Movie', 'Rating']].sample(20000), sp.Reader())\n",
        "\n",
        "benchmark = []\n",
        "# Iterate over all algorithms\n",
        "for algorithm in [sp.SVD(), sp.SVDpp(), sp.SlopeOne(), sp.NMF(), sp.NormalPredictor(), sp.KNNBaseline(), sp.KNNBasic(), sp.KNNWithMeans(), sp.KNNWithZScore(), sp.BaselineOnly(), sp.CoClustering()]:\n",
        "    # Perform cross validation\n",
        "    results = cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=3, verbose=False)\n",
        "    \n",
        "    # Get results & append algorithm name\n",
        "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
        "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
        "    \n",
        "    # Store data\n",
        "    benchmark.append(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDTqXmlMLtV5"
      },
      "source": [
        "# Store results\n",
        "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse', ascending=False)\n",
        "\n",
        "# Get data\n",
        "data = surprise_results[['test_rmse', 'test_mae']]\n",
        "grid = data.values\n",
        "\n",
        "# Create axis labels\n",
        "x_axis = [label.split('_')[1].upper() for label in data.columns.tolist()]\n",
        "y_axis = data.index.tolist()\n",
        "\n",
        "x_label = 'Function'\n",
        "y_label = 'Algorithm'\n",
        "\n",
        "\n",
        "# Get annotations and hovertext\n",
        "hovertexts = []\n",
        "annotations = []\n",
        "for i, y_value in enumerate(y_axis):\n",
        "    row = []\n",
        "    for j, x_value in enumerate(x_axis):\n",
        "        annotation = grid[i, j]\n",
        "        row.append('Error: {:.3f}<br>{}: {}<br>{}: {}<br>Fit Time: {:.3f}s<br>Test Time: {:.3f}s'.format(annotation, y_label, y_value ,x_label, x_value, surprise_results.loc[y_value]['fit_time'], surprise_results.loc[y_value]['test_time']))\n",
        "        annotations.append(dict(x=x_value, y=y_value, text='{:.3f}'.format(annotation), ax=0, ay=0, font=dict(color='#000000')))\n",
        "    hovertexts.append(row)\n",
        "\n",
        "# Create trace\n",
        "trace = go.Heatmap(x = x_axis,\n",
        "                   y = y_axis,\n",
        "                   z = data.values,\n",
        "                   text = hovertexts,\n",
        "                   hoverinfo = 'text',\n",
        "                   colorscale = 'Picnic',\n",
        "                   colorbar = dict(title = 'Error'))\n",
        "\n",
        "# Create layout\n",
        "layout = go.Layout(title = 'Crossvalidated Comparison Of Surprise Algorithms',\n",
        "                   xaxis = dict(title = x_label),\n",
        "                   yaxis = dict(title = y_label,\n",
        "                                tickangle = -40),\n",
        "                   annotations = annotations)\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}